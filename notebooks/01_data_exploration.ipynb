{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Land Cover Segmentation - Data Exploration\n",
    "\n",
    "This notebook explores the land cover dataset and visualizes class distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from src.utils import load_config\n",
    "from src.data import LandCoverDataset, get_transforms\n",
    "from src.utils.visualization import visualize_predictions, hex_to_rgb\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config('../config/unet_config.yaml')\n",
    "\n",
    "print(\"Class Information:\")\n",
    "class_names = config.get('classes.class_names')\n",
    "class_colors = config.get('classes.class_colors')\n",
    "\n",
    "for i, (name, color) in enumerate(zip(class_names, class_colors)):\n",
    "    print(f\"{i}: {name} - {color}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This assumes you have data in the specified directories\n",
    "# Update paths according to your data location\n",
    "\n",
    "try:\n",
    "    # Load dataset\n",
    "    transforms = get_transforms('val', config.get('data'))\n",
    "    dataset = LandCoverDataset(\n",
    "        images_dir=config.get('paths.train_images'),\n",
    "        masks_dir=config.get('paths.train_masks'),\n",
    "        transform=transforms\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset size: {len(dataset)} samples\")\n",
    "    \n",
    "    # Sample a few examples\n",
    "    if len(dataset) > 0:\n",
    "        sample_image, sample_mask = dataset[0]\n",
    "        print(f\"Image shape: {sample_image.shape}\")\n",
    "        print(f\"Mask shape: {sample_mask.shape}\")\n",
    "        print(f\"Unique classes in sample: {torch.unique(sample_mask)}\")\n",
    "    else:\n",
    "        print(\"No data found - using synthetic examples\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not load dataset: {e}\")\n",
    "    print(\"Using synthetic examples for demonstration\")\n",
    "    dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected class distribution from problem statement\n",
    "expected_distribution = {\n",
    "    'Bareland': 1.5,\n",
    "    'Rangeland': 22.9,\n",
    "    'Developed space': 16.1,\n",
    "    'Road': 6.7,\n",
    "    'Tree': 20.2,\n",
    "    'Water': 3.3,\n",
    "    'Agriculture land': 13.7,\n",
    "    'Building': 15.6\n",
    "}\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar plot\n",
    "classes = list(expected_distribution.keys())\n",
    "percentages = list(expected_distribution.values())\n",
    "colors = [f\"{color}\" for color in class_colors]\n",
    "\n",
    "bars = ax1.bar(classes, percentages, color=[f\"{hex_to_rgb(c)[0]/255:.2f}, {hex_to_rgb(c)[1]/255:.2f}, {hex_to_rgb(c)[2]/255:.2f}\" for c in class_colors])\n",
    "ax1.set_title('Expected Class Distribution')\n",
    "ax1.set_ylabel('Percentage (%)')\n",
    "ax1.set_xticklabels(classes, rotation=45, ha='right')\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             f'{pct}%', ha='center', va='bottom')\n",
    "\n",
    "# Pie chart\n",
    "wedges, texts, autotexts = ax2.pie(percentages, labels=classes, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Class Distribution (Pie Chart)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Palette Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create color palette visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 3))\n",
    "\n",
    "# Create color swatches\n",
    "for i, (name, color) in enumerate(zip(class_names, class_colors)):\n",
    "    rgb = hex_to_rgb(color)\n",
    "    rgb_norm = [c/255.0 for c in rgb]\n",
    "    \n",
    "    # Draw color rectangle\n",
    "    rect = plt.Rectangle((i, 0), 1, 1, facecolor=rgb_norm, edgecolor='black', linewidth=1)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Add text label\n",
    "    ax.text(i+0.5, 0.5, name, ha='center', va='center', \n",
    "            rotation=45, fontsize=10, fontweight='bold',\n",
    "            color='white' if sum(rgb) < 384 else 'black')\n",
    "    \n",
    "    # Add hex code\n",
    "    ax.text(i+0.5, -0.2, color, ha='center', va='center', \n",
    "            fontsize=8, color='black')\n",
    "\n",
    "ax.set_xlim(0, len(class_names))\n",
    "ax.set_ylim(-0.3, 1.1)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title('Land Cover Class Color Palette', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic examples if real data is not available\n",
    "def create_synthetic_example(size=(256, 256)):\n",
    "    \"\"\"Create a synthetic land cover example.\"\"\"\n",
    "    # Create synthetic image\n",
    "    image = np.random.rand(*size, 3).astype(np.float32)\n",
    "    \n",
    "    # Create synthetic mask with different regions\n",
    "    mask = np.zeros(size, dtype=np.int64)\n",
    "    \n",
    "    # Add different land cover types\n",
    "    h, w = size\n",
    "    \n",
    "    # Water (class 5) - bottom area\n",
    "    mask[int(0.8*h):, :] = 5\n",
    "    \n",
    "    # Trees (class 4) - left side\n",
    "    mask[:int(0.7*h), :int(0.3*w)] = 4\n",
    "    \n",
    "    # Agriculture (class 6) - center\n",
    "    mask[int(0.2*h):int(0.6*h), int(0.3*w):int(0.7*w)] = 6\n",
    "    \n",
    "    # Buildings (class 7) - top right\n",
    "    mask[:int(0.3*h), int(0.7*w):] = 7\n",
    "    \n",
    "    # Roads (class 3) - connecting paths\n",
    "    mask[int(0.4*h):int(0.5*h), :] = 3  # horizontal road\n",
    "    mask[:, int(0.6*w):int(0.65*w)] = 3  # vertical road\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "# Use real data if available, otherwise synthetic\n",
    "if dataset is not None and len(dataset) > 0:\n",
    "    # Use real data\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for i in range(min(4, len(dataset))):\n",
    "        img, mask = dataset[i]\n",
    "        # Convert tensor to numpy for visualization\n",
    "        img_np = img.permute(1, 2, 0).numpy()\n",
    "        mask_np = mask.numpy()\n",
    "        images.append(img_np)\n",
    "        masks.append(mask_np)\n",
    "else:\n",
    "    # Use synthetic data\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for i in range(4):\n",
    "        img, mask = create_synthetic_example()\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "# Visualize examples\n",
    "from src.utils.visualization import mask_to_rgb, create_color_map\n",
    "\n",
    "color_map = create_color_map(class_colors)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(4):\n",
    "    # Original image\n",
    "    axes[0, i].imshow(images[i])\n",
    "    axes[0, i].set_title(f'Sample {i+1} - Original')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Segmentation mask\n",
    "    mask_rgb = mask_to_rgb(masks[i], color_map)\n",
    "    axes[1, i].imshow(mask_rgb)\n",
    "    axes[1, i].set_title(f'Sample {i+1} - Segmentation')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class statistics from the samples\n",
    "if len(masks) > 0:\n",
    "    # Count pixels for each class across all samples\n",
    "    class_counts = {i: 0 for i in range(len(class_names))}\n",
    "    total_pixels = 0\n",
    "    \n",
    "    for mask in masks:\n",
    "        unique, counts = np.unique(mask, return_counts=True)\n",
    "        for class_id, count in zip(unique, counts):\n",
    "            if class_id < len(class_names):\n",
    "                class_counts[class_id] += count\n",
    "                total_pixels += count\n",
    "    \n",
    "    # Calculate percentages\n",
    "    sample_distribution = {}\n",
    "    for class_id, count in class_counts.items():\n",
    "        if class_id < len(class_names):\n",
    "            percentage = (count / total_pixels) * 100 if total_pixels > 0 else 0\n",
    "            sample_distribution[class_names[class_id]] = percentage\n",
    "    \n",
    "    # Create comparison plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    x_pos = np.arange(len(class_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    expected_vals = [expected_distribution.get(name, 0) for name in class_names]\n",
    "    sample_vals = [sample_distribution.get(name, 0) for name in class_names]\n",
    "    \n",
    "    bars1 = ax.bar(x_pos - width/2, expected_vals, width, label='Expected', alpha=0.8)\n",
    "    bars2 = ax.bar(x_pos + width/2, sample_vals, width, label='Sample Data', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Land Cover Classes')\n",
    "    ax.set_ylabel('Percentage (%)')\n",
    "    ax.set_title('Expected vs Sample Class Distribution')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nClass Distribution Comparison:\")\n",
    "    print(f\"{'Class':<20} {'Expected %':<12} {'Sample %':<12} {'Difference':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name in class_names:\n",
    "        exp_val = expected_distribution.get(name, 0)\n",
    "        sample_val = sample_distribution.get(name, 0)\n",
    "        diff = sample_val - exp_val\n",
    "        print(f\"{name:<20} {exp_val:<12.1f} {sample_val:<12.1f} {diff:<12.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Insights and Recommendations\n",
    "\n",
    "Based on the exploration above, here are key insights:\n",
    "\n",
    "1. **Class Imbalance**: The dataset shows significant class imbalance, with Rangeland (22.9%) and Tree (20.2%) being the most common classes, while Bareland (1.5%) and Water (3.3%) are rare.\n",
    "\n",
    "2. **Color Palette**: Each class has a distinct color for easy visualization and interpretation.\n",
    "\n",
    "3. **Recommendations**:\n",
    "   - Use class weights in loss functions to handle imbalance\n",
    "   - Consider data augmentation for underrepresented classes\n",
    "   - Monitor per-class performance metrics during training\n",
    "   - Use appropriate evaluation metrics (IoU, F1-score) that account for imbalance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}